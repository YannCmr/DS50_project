{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "\n",
    "This notebook aim to split the data in a smaller dataset for training and testing.\n",
    "\n",
    "It aim to avoid biais by :\n",
    "- Stratified Sampling \n",
    "- Perceptual Hashing / Feature Embeddings + kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the path\n",
    "And check if the folder exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_PATH = \"../\"\n",
    "\n",
    "INPUT_DIR = DATA_FOLDER_PATH + \"00_archive/data/\"\n",
    "OUTPUT_DIR = DATA_FOLDER_PATH + \"00_archive/data_samples/\"\n",
    "\n",
    "file_types = [\"train\", \"test\", \"val\"]\n",
    "subdirectories = [\"Coccidiosis\", \"Healthy\", \"New Castle Disease\", \"Salmonella\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All folder structures are in place.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def check_and_create_path(verbose = False):\n",
    "    \"\"\"\n",
    "    Check if the input directory structure exists and create the output directory structure if it doesn't.\n",
    "\n",
    "    Parameters:\n",
    "        - verbose (bool): If True, print detailed information about the directory structure.\n",
    "\n",
    "    Return :\n",
    "        - None\n",
    "    \"\"\"\n",
    "    # Check input structure\n",
    "    for file_type in file_types:\n",
    "        input_path = os.path.join(INPUT_DIR, file_type)\n",
    "        if not os.path.isdir(input_path):\n",
    "            raise FileNotFoundError(f\"‚ùå Input directory does not exist: {input_path}\")\n",
    "        if verbose :\n",
    "            print(f\"‚úÖ Found directory: {input_path}\")\n",
    "\n",
    "        for subdirectory in subdirectories:\n",
    "            sub_path = os.path.join( input_path, subdirectory)\n",
    "            if not os.path.isdir(sub_path):\n",
    "                raise FileNotFoundError(f\"‚ùå Subdirectory missing: {sub_path}\")\n",
    "            if verbose :\n",
    "                print(f\"  ‚úÖ Found subdirectory: {sub_path}\")\n",
    "\n",
    "    #  Check/create output directory\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "        if verbose :\n",
    "            print(f\"üìÅ Output directory created: {OUTPUT_DIR}\")\n",
    "    else:\n",
    "        if verbose :\n",
    "            print(f\"‚úÖ Output directory already exists: {OUTPUT_DIR}\")\n",
    "\n",
    "    # Create output structure if not exist\n",
    "    for file_type in file_types:\n",
    "        output_path = os.path.join(OUTPUT_DIR, file_type)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path, exist_ok=True)\n",
    "            if verbose :\n",
    "                print(f\"üìÅ Created output directory: {output_path}\")\n",
    "        else:\n",
    "            if verbose :\n",
    "                print(f\"‚úÖ Output directory already exists: {output_path}\")\n",
    "\n",
    "        for subdirectory in subdirectories:\n",
    "            sub_path = os.path.join(output_path, subdirectory)\n",
    "            if not os.path.exists(sub_path):\n",
    "                os.makedirs(sub_path, exist_ok=True)\n",
    "                if verbose :\n",
    "                    print(f\"üìÅ Created output subdirectory: {sub_path}\")\n",
    "            else:\n",
    "                if verbose :\n",
    "                    print(f\"‚úÖ Output subdirectory already exists: {sub_path}\")\n",
    "\n",
    "    print(f\"‚úÖ All folder structures are in place.\")\n",
    "\n",
    "check_and_create_path(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned output samples directory: ../archive/data_samples/\n"
     ]
    }
   ],
   "source": [
    "def clean_directory(directory):\n",
    "    \"\"\"\n",
    "    Remove all files and subdirectories in a given directory.\n",
    "\n",
    "    Parameters:\n",
    "        - directory (str): The path to the directory to be cleaned.\n",
    "\n",
    "    Return :\n",
    "        - None\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "\n",
    "def clean_output_samples():\n",
    "    \"\"\"\n",
    "    Clean the output samples directory by removing all files and subdirectories.\n",
    "\n",
    "    Parameters:\n",
    "        - None\n",
    "\n",
    "    Return :\n",
    "        - None\n",
    "    \"\"\"\n",
    "    for file_type in file_types:\n",
    "        output_path = os.path.join(OUTPUT_DIR, file_type)\n",
    "        for subdirectory in subdirectories:\n",
    "            sub_path = os.path.join(output_path, subdirectory)\n",
    "            clean_directory(sub_path)\n",
    "    print(f\"Cleaned output samples directory: {OUTPUT_DIR}\")\n",
    "\n",
    "clean_output_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampled data\n",
    "\n",
    "V1 : basic stratified split per class and per folder using `train_test_split` from `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in train: 400000\n",
      "  Coccidiosis: 100000 files\n",
      "  Healthy: 100000 files\n",
      "  New Castle Disease: 100000 files\n",
      "  Salmonella: 100000 files\n",
      "Total files in test: 70677\n",
      "  Coccidiosis: 18752 files\n",
      "  Healthy: 17412 files\n",
      "  New Castle Disease: 15888 files\n",
      "  Salmonella: 18625 files\n",
      "Total files in val: 40000\n",
      "  Coccidiosis: 10000 files\n",
      "  Healthy: 10000 files\n",
      "  New Castle Disease: 10000 files\n",
      "  Salmonella: 10000 files\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#lets see how much data we have\n",
    "def count_files_in_directory(directory):\n",
    "    \"\"\"\n",
    "    Count the number of files in a given directory.\n",
    "\n",
    "    Parameters:\n",
    "        - directory (str): The path to the directory to be counted.\n",
    "\n",
    "    Return :\n",
    "        - int: The number of files in the directory.\n",
    "    \"\"\"\n",
    "    return sum(len(files) for _, _, files in os.walk(directory))\n",
    "\n",
    "def count_files_in_subdirectories(directory):\n",
    "    \"\"\"\n",
    "    Count the number of files in all subdirectories of a given directory.\n",
    "\n",
    "    Parameters:\n",
    "        - directory (str): The path to the directory to be counted.\n",
    "\n",
    "    Return :\n",
    "        - int: The total number of files in all subdirectories.\n",
    "    \"\"\"\n",
    "    total_files = 0\n",
    "    for subdirectory in subdirectories:\n",
    "        sub_path = os.path.join(directory, subdirectory)\n",
    "        total_files += count_files_in_directory(sub_path)\n",
    "    return total_files\n",
    "\n",
    "def count_files_in_all_directories():\n",
    "    \"\"\"\n",
    "    Count the number of files in all directories and subdirectories.\n",
    "\n",
    "    Parameters:\n",
    "        - None\n",
    "\n",
    "    Return :\n",
    "        - None\n",
    "    \"\"\"\n",
    "    for file_type in file_types:\n",
    "        input_path = os.path.join(INPUT_DIR, file_type)\n",
    "        total_files = count_files_in_subdirectories(input_path)\n",
    "        print(f\"Total files in {file_type}: {total_files}\")\n",
    "        for subdirectory in subdirectories:\n",
    "            sub_path = os.path.join(input_path, subdirectory)\n",
    "            num_files = count_files_in_directory(sub_path)\n",
    "            print(f\"  {subdirectory}: {num_files} files\")\n",
    "\n",
    "print(\"-----------------------------------------------------\")\n",
    "count_files_in_all_directories()\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_PER_CLASS = 1000  # arbitrary number of samples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images copied to ../archive/data_samples/train\\Coccidiosis\n",
      "1000 images copied to ../archive/data_samples/train\\Healthy\n",
      "1000 images copied to ../archive/data_samples/train\\New Castle Disease\n",
      "1000 images copied to ../archive/data_samples/train\\Salmonella\n",
      "1000 images copied to ../archive/data_samples/test\\Coccidiosis\n",
      "1000 images copied to ../archive/data_samples/test\\Healthy\n",
      "1000 images copied to ../archive/data_samples/test\\New Castle Disease\n",
      "1000 images copied to ../archive/data_samples/test\\Salmonella\n",
      "1000 images copied to ../archive/data_samples/val\\Coccidiosis\n",
      "1000 images copied to ../archive/data_samples/val\\Healthy\n",
      "1000 images copied to ../archive/data_samples/val\\New Castle Disease\n",
      "1000 images copied to ../archive/data_samples/val\\Salmonella\n",
      "Fixed-count sampling done!\n"
     ]
    }
   ],
   "source": [
    "def fixed_count_sample(verbose=False):\n",
    "    \"\"\"\n",
    "    Sample a fixed number of images per class per folder and copy them to the output directory.\n",
    "    \"\"\"\n",
    "    for file_type in file_types:\n",
    "        for subdirectory in subdirectories:\n",
    "            input_path = os.path.join(INPUT_DIR, file_type, subdirectory)\n",
    "            output_path = os.path.join(OUTPUT_DIR, file_type, subdirectory)\n",
    "\n",
    "            # List images\n",
    "            images = [f for f in os.listdir(input_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if len(images) == 0:\n",
    "                print(f\"No images found in {input_path}\")\n",
    "                continue\n",
    "\n",
    "            # Adjust if fewer images than the sample size\n",
    "            sample_count = min(SAMPLES_PER_CLASS, len(images))\n",
    "            sampled_images = random.sample(images, sample_count)\n",
    "\n",
    "            # Copy sampled images\n",
    "            for img in sampled_images:\n",
    "                src = os.path.join(input_path, img)\n",
    "                dst = os.path.join(output_path, img)\n",
    "                shutil.copy2(src, dst)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{sample_count} images copied to {output_path}\")\n",
    "\n",
    "    print(\"Fixed-count sampling done!\")\n",
    "\n",
    "clean_output_samples()\n",
    "fixed_count_sample(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampled data \n",
    "\n",
    "V2 : ResNet + KMeans Diversity Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned output samples directory: ../archive/data_samples/\n"
     ]
    }
   ],
   "source": [
    "clean_output_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\UTBM\\INFO4\\07_DS50\\DS50_project\\venvProjetDS50\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\UTBM\\INFO4\\07_DS50\\DS50_project\\venvProjetDS50\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "                                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 94\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müéØ Diversity-based sampling complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# üöÄ Run it\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[43mdiverse_sample_with_kmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mdiverse_sample_with_kmeans\u001b[39m\u001b[34m(verbose)\u001b[39m\n\u001b[32m     56\u001b[39m valid_paths = []\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m tqdm(image_paths, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müîç \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     emb = \u001b[43mextract_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m emb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     61\u001b[39m         embeddings.append(emb)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mextract_embedding\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_embedding\u001b[39m(image_path):\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         img = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m.convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m         img_tensor = preprocess(img).unsqueeze(\u001b[32m0\u001b[39m).to(DEVICE)\n\u001b[32m     33\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\UTBM\\INFO4\\07_DS50\\DS50_project\\venvProjetDS50\\Lib\\site-packages\\PIL\\Image.py:3465\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3462\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3465\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3466\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# WARNING : too long, will be lunch later\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Parameters\n",
    "SAMPLES_PER_CLASS = 30\n",
    "IMAGE_SIZE = 224\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load Pretrained ResNet (remove final classification layer)\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = torch.nn.Identity()\n",
    "resnet = resnet.to(DEVICE).eval()\n",
    "\n",
    "# Preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def extract_embedding(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "        img_tensor = preprocess(img).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            embedding = resnet(img_tensor).squeeze().cpu().numpy()\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def diverse_sample_with_kmeans(verbose=False):\n",
    "    \"\"\"\n",
    "    For each class in each file_type folder, extract embeddings, perform KMeans,\n",
    "    and copy the most diverse images (closest to cluster centers).\n",
    "    \"\"\"\n",
    "    for file_type in file_types:\n",
    "        for subdirectory in subdirectories:\n",
    "            input_path = os.path.join(INPUT_DIR, file_type, subdirectory)\n",
    "            output_path = os.path.join(OUTPUT_DIR, file_type, subdirectory)\n",
    "\n",
    "            # List images\n",
    "            images = [f for f in os.listdir(input_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            image_paths = [os.path.join(input_path, f) for f in images]\n",
    "\n",
    "            # Extract embeddings\n",
    "            embeddings = []\n",
    "            valid_paths = []\n",
    "\n",
    "            for path in tqdm(image_paths, desc=f\"üîç {file_type}/{subdirectory}\", leave=False):\n",
    "                emb = extract_embedding(path)\n",
    "                if emb is not None:\n",
    "                    embeddings.append(emb)\n",
    "                    valid_paths.append(path)\n",
    "\n",
    "            if len(valid_paths) == 0:\n",
    "                print(f\"No valid images found in {input_path}\")\n",
    "                continue\n",
    "\n",
    "            # KMeans clustering\n",
    "            n_clusters = min(SAMPLES_PER_CLASS, len(valid_paths))\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            kmeans.fit(embeddings)\n",
    "\n",
    "            # Find image closest to each cluster center\n",
    "            selected_paths = []\n",
    "            for center in kmeans.cluster_centers_:\n",
    "                dists = np.linalg.norm(np.array(embeddings) - center, axis=1)\n",
    "                idx = np.argmin(dists)\n",
    "                selected_paths.append(valid_paths[idx])\n",
    "\n",
    "            # Remove duplicates\n",
    "            selected_paths = list(set(selected_paths))\n",
    "\n",
    "            # Copy selected images\n",
    "            for src in selected_paths:\n",
    "                dst = os.path.join(output_path, os.path.basename(src))\n",
    "                shutil.copy2(src, dst)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{len(selected_paths)} diverse images copied to {output_path}\")\n",
    "\n",
    "    print(\"üéØ Diversity-based sampling complete!\")\n",
    "\n",
    "# üöÄ Run it\n",
    "diverse_sample_with_kmeans(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvProjetDS50",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
